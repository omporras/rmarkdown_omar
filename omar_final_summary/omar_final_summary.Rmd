---
title: Catering for prawns, in pursuit of sustainability in the aquaculture industry
subtitle: 
author:  Omar Mendoza Porras
affiliation: CSIRO Livestock and Aquaculture # Or group/team
photo: resources/img/jpprawn.jpg

short_title: Optional short title

output: DSreport::project_summary
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(
  results = 'asis',
  echo = FALSE,
  warning = FALSE,
  message = FALSE,
  fig.align = 'center'
)

#Load libraries
library(tidyverse)
library(gapminder)
library(kableExtra)
```


# Introduction
I am an oceanographer with experience in biotechnology, mass spectrometry and aquaculture. Before Data School I did not code at all and my data processing consisted of using vendor specific software (expensive licenses) to visualise and process data. I also did lots of clicking and data sorting in Excel. It was not enjoyable.


# My Project
The goal of my project(s) is to identify peptide markers derived from proteins that are expressed in different prawn tissues as a result of using different functional diets. Proteomics is used as a main tool. The long term goal is to achieve sustainability in the aquaculture sector throughout the use of diets manufactured from renewable sources.  


## Preliminary results

In this study, 252 protein peptides were measured in prawn hepatopancreas two hours post-feeding. We used Sequential Window Acquisition of all Theoretical mass spectra (SWATH-MS) to detect and identify these protein peptides.   
```{r importing raw data file followed by producing a long version of it}
ral <- read_csv("data/Ral17_3.csv")
#view(ral)
#make long format
ral_long <- ral %>% 
  gather(peptide, concentration, -replicate, -diet)
#view(ral_long)

ggplot(ral_long, aes(x=peptide, y = concentration, colour = diet)) +
  geom_point(size = 0.6) +
  scale_y_log10()
```



**Tables**
```{r #sample table for html markdown. Filter by replicate 1 to provide a sample of each treatment tested in this work}
Rep1<-filter(ral_long, replicate == 1)

```


```{r mytable, out.width='100%'}
knitr::kable(head(Rep1, n = 4), format = "html", caption = "Differential protein expression in hepatopancreas of black tiger prawn _Penaeus monodon_ in response to specific feeding formulations") %>% 
  kable_styling("striped")
```


**Plots from R**
```{r standard-plot, out.width='60%', fig.align='center', fig.height= 4, fig.width=6, fig.cap="Protein expression in hepatopancreas of prawns fed different diets"}
#Obtain mean of peptide expression of each peptide sharing same accession number to represent protein expression}

#separate accession number from peptide sequence
ral_long_separated<- ral_long %>% 
  separate(peptide, into = c('pept', 'ide'))
#view(ral_long_separated)
#rename heading from table
ral_final<-rename(ral_long_separated, Diet = diet, Replicate = replicate, Peptide = pept, Accession = ide, Concentration = concentration)
#view(ral_final)
#remove trypsin and reversed derived peptides
ral_final<-subset(ral_final, Accession!="TRYP")
ral_final<-subset(ral_final, Accession!="RRtr")
#view(ral_final)

#Obtain general protein expression derived from accession numbers

ral_final_by_accession <-group_by(ral_final, Accession, Diet)
#view(ral_final_by_accession) 
general_protein_expression<-summarise(ral_final_by_accession, mean_Concentration = mean(Concentration))
#view(general_protein_expression)
ggplot(general_protein_expression, aes(x=Accession, y = mean_Concentration, colour = Diet)) +
  geom_point () +
  scale_y_log10() +
  scale_color_brewer(palette = "Set1") +
  theme(legend.position = "bottom")

# Identify highly expressed proteins
#ggplot(general_protein_expression, aes(x=Accession, y = mean_Concentration, colour = Diet, label = Accession)) +
 # geom_point () +
  #geom_label(size = 2) +
  #scale_y_log10() +
  #scale_color_brewer(palette = "Set1") +
  #theme(legend.position = "bottom")

```
# Statistics

```{r **Statistics**}
ral_fishmeal_novacq <- filter(general_protein_expression, Diet %in% c("Fishmeal","Novacq"))

#view(ral_fishmeal_novacq)

ral_fishmeal_novacq_t <- t.test(mean_Concentration ~ Diet, data = ral_fishmeal_novacq)

ral_fishmeal_novacq_t

ral_krillmeal_novacq <- filter(general_protein_expression, Diet %in% c("Krillmeal","Novacq"))

#view(ral_krillmeal_novacq)

ral_krillmeal_novacq_t <- t.test(mean_Concentration ~ Diet, data = ral_krillmeal_novacq)

ral_krillmeal_novacq_t

#Fasting

ral_fasting_novacq <- filter(general_protein_expression, Diet %in% c("Fasting","Novacq"))

#view(ral_fasting_novacq)

ral_fasting_novacq_t <- t.test(mean_Concentration ~ Diet, data = ral_fasting_novacq)

ral_fasting_novacq_t


```




# My Digital Toolbox

The tool that I have used the most  in my projects is Tidyverse. I currenlty use it to generate lists of proteins identified using proteomics and to filter protein redundancy. I am also focusing on learning more about ggplot2

# My time went ...

I spent a significant amount of time understanding the underlying logic of the process of making dataframes "tidy". I was not surprised that Data School would be a challenge but at the same time I was very excited to start learning a coding language. I solved some of my challenges by rewatching the webex recordings and reading at forums in the internet.  

# Next steps

I will focus in mastering R for now but I am sure that I am not going back to excel. I believe that in the future I would like to become a bioinformatician/statistician to complement my current skills. I would like to learn bash, SQL, SAS and python.

# My Data School Experience

I wish I had attended week 1 at data school to personally meet everyone. Aside from that my experience in data school has been rich. I have been able to use my newly acquired data school skills in my daily work. A specific example of this has been producing an output (a protein list) that tells me the degree of protein redundancy that I have in my proteomics work. This was a task that would take me between 3-4 hours in excel. Now it takes me 45 seconds. Very embarrasing. Never again. At a personal level, being able to be more efficient with my time makes me feel more at ease and happy.

